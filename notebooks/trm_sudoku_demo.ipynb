{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afdbda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import adam2\n"
     ]
    }
   ],
   "source": [
    "# conda env: scalinglaws\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.nn.modules.utils import compute_lr\n",
    "from src.nn.utils.constants import IGNORE_LABEL_ID\n",
    "from src.nn.optimizers.muon import Muon\n",
    "\n",
    "# pip install adam-atan2-pytorch\n",
    "try:\n",
    "    from adam_atan2_pytorch import AdamAtan2\n",
    "    print(f\"*\"*60)\n",
    "    print(\"Imported AdamATan2 successfully\")\n",
    "except ImportError:\n",
    "    print(\"Failed to import adam2\")\n",
    "\n",
    "from lightning import LightningModule\n",
    "\n",
    "from src.nn.modules.sparse_embeddings import (\n",
    "    CastedSparseEmbedding,\n",
    "    CastedSparseEmbeddingSignSGD_Distributed,\n",
    ")\n",
    "from src.nn.modules.trm_block import (\n",
    "    CastedEmbedding,\n",
    "    CastedLinear,\n",
    "    ReasoningBlock,\n",
    "    ReasoningBlockConfig,\n",
    "    ReasoningModule,\n",
    "    RotaryEmbedding,\n",
    "    RotaryEmbedding2D,\n",
    ")\n",
    "from src.nn.modules.utils import stablemax_cross_entropy, trunc_normal_init_\n",
    "from src.nn.utils import RankedLogger\n",
    "from src.nn.data.sudoku_datamodule import SudokuDataModule\n",
    "\n",
    "log = RankedLogger(__name__, rank_zero_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad5bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sudoku_text(batch, idx=0, grid_size=6):\n",
    "    input_tensor = batch['input'][idx]\n",
    "    label_tensor = batch['output'][idx]\n",
    "    \n",
    "    # 1. We need to determine the max_grid_size used by the dataset to reshape correctly.\n",
    "    # We can infer it from the tensor length: sqrt(sequence_length)\n",
    "    seq_len = input_tensor.numel()\n",
    "    max_grid_size = int(seq_len**0.5)\n",
    "\n",
    "    # Box dimensions\n",
    "    if grid_size == 6: box_rows, box_cols = 2, 3\n",
    "    elif grid_size == 9: box_rows, box_cols = 3, 3\n",
    "    elif grid_size == 4: box_rows, box_cols = 2, 2\n",
    "    else: box_rows, box_cols = 2, 3\n",
    "\n",
    "    def decode_cell(val):\n",
    "        val = val.item()\n",
    "        if val == 2: return \".\"\n",
    "        if val > 2: return str(val - 2)\n",
    "        return \"?\" # 0=PAD or 1=EOS\n",
    "\n",
    "    def render_grid(tensor):\n",
    "        # CORRECTED LOGIC:\n",
    "        # 1. Reshape using the FULL max_grid_size to restore 2D structure\n",
    "        full_grid = tensor.reshape(max_grid_size, max_grid_size)\n",
    "        \n",
    "        # 2. Crop to the actual grid_size (top-left corner)\n",
    "        grid = full_grid[:grid_size, :grid_size]\n",
    "        \n",
    "        lines = []\n",
    "        dash_segment = \"-\" * (box_cols * 2 + 1)\n",
    "        h_sep = \"+\" + \"+\".join([dash_segment] * (grid_size // box_cols)) + \"+\"\n",
    "        \n",
    "        for r in range(grid_size):\n",
    "            if r % box_rows == 0:\n",
    "                lines.append(h_sep)\n",
    "            \n",
    "            row_str = \"|\"\n",
    "            for c in range(grid_size):\n",
    "                cell = decode_cell(grid[r, c])\n",
    "                row_str += f\" {cell}\"\n",
    "                if (c + 1) % box_cols == 0:\n",
    "                    row_str += \" |\"\n",
    "            lines.append(row_str)\n",
    "        lines.append(h_sep)\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    # Stats calculation (only on valid crop)\n",
    "    full_input_2d = input_tensor.reshape(max_grid_size, max_grid_size)\n",
    "    valid_input_crop = full_input_2d[:grid_size, :grid_size]\n",
    "    \n",
    "    givens = (valid_input_crop > 2).sum().item()\n",
    "    empty = (valid_input_crop == 2).sum().item()\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Sample {idx} (grid_size={grid_size}x{grid_size})\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Givens: {givens}, Empty: {empty}\\n\")\n",
    "    \n",
    "    print(\"Puzzle:\")\n",
    "    print(render_grid(input_tensor))\n",
    "    print(\"\\nSolution:\")\n",
    "    print(render_grid(label_tensor))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8b4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TRMInnerCarry:\n",
    "    z_H: torch.Tensor\n",
    "    z_L: torch.Tensor\n",
    "\n",
    "@dataclass\n",
    "class TRMCarry:\n",
    "    inner_carry: TRMInnerCarry\n",
    "    steps: torch.Tensor\n",
    "    halted: torch.Tensor\n",
    "    current_data: Dict[str, torch.Tensor]\n",
    "\n",
    "class TRMModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 512,\n",
    "        num_layers: int = 2,\n",
    "        num_heads: int = 8,\n",
    "        max_grid_size: int = 30,\n",
    "        ffn_expansion: int = 2,\n",
    "        puzzle_emb_dim: int = 512,\n",
    "        puzzle_emb_len: int = 16,\n",
    "        pos_emb_type: str = \"1d\",\n",
    "        use_mlp_t: bool = False,\n",
    "        use_conv_swiglu: bool = False,\n",
    "        use_board_swiglu: bool = False,\n",
    "        vocab_size: int = 0,\n",
    "        num_puzzles: int = 0,\n",
    "        batch_size: int = 0,\n",
    "        pad_value: int = -1,\n",
    "        seq_len: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pad_value = pad_value\n",
    "        self.forward_dtype = torch.bfloat16\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Token embeddings\n",
    "        self.embed_scale = math.sqrt(self.hidden_size)\n",
    "        embed_init_std = 1.0 / self.embed_scale\n",
    "\n",
    "        # Input embedding\n",
    "        self.input_embedding = CastedEmbedding(\n",
    "            vocab_size, hidden_size, init_std=embed_init_std, cast_to=self.forward_dtype\n",
    "        )\n",
    "\n",
    "        # Puzzle embedding\n",
    "        if puzzle_emb_dim > 0:\n",
    "            self.puzzle_emb = CastedSparseEmbedding(\n",
    "                num_embeddings=num_puzzles,\n",
    "                embedding_dim=puzzle_emb_dim,\n",
    "                batch_size=batch_size,\n",
    "                init_std=0.0,\n",
    "                cast_to=self.forward_dtype,\n",
    "            )\n",
    "            self.puzzle_emb_len = puzzle_emb_len\n",
    "        else:\n",
    "            self.puzzle_emb = None\n",
    "            self.puzzle_emb_len = 0\n",
    "        \n",
    "        # Positional embeddings\n",
    "        if pos_emb_type == \"2d\":\n",
    "            self.pos_embedding = RotaryEmbedding2D(\n",
    "                dim=self.hidden_size // num_heads,\n",
    "                prefix_len=self.puzzle_emb_len, # Use self.puzzle_emb_len\n",
    "                max_grid_size=int(math.sqrt(self.seq_len)), \n",
    "                base=10000,\n",
    "            )\n",
    "        elif pos_emb_type == \"1d\":\n",
    "            self.pos_embedding = RotaryEmbedding(\n",
    "                dim=self.hidden_size // num_heads,\n",
    "                max_position_embeddings=self.seq_len + self.puzzle_emb_len, # Use self.puzzle_emb_len\n",
    "                base=10000,\n",
    "            )\n",
    "        \n",
    "        if not use_mlp_t:\n",
    "            assert pos_emb_type is not None, \"Rotary embeddings required if using attention\"\n",
    "\n",
    "        # Reasoning Block\n",
    "        reasoning_config = ReasoningBlockConfig(\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_heads=num_heads,\n",
    "            expansion=ffn_expansion,\n",
    "            rms_norm_eps=1e-5,\n",
    "            seq_len=self.seq_len,\n",
    "            mlp_t=use_mlp_t,\n",
    "            puzzle_emb_ndim=puzzle_emb_dim,\n",
    "            puzzle_emb_len=self.puzzle_emb_len, # Use self.puzzle_emb_len\n",
    "            use_conv_swiglu=use_conv_swiglu,\n",
    "            use_board_swiglu=use_board_swiglu,\n",
    "            rows = max_grid_size,\n",
    "            cols = max_grid_size\n",
    "        )\n",
    "\n",
    "        self.lenet = ReasoningModule(\n",
    "            layers=[ReasoningBlock(reasoning_config) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        self.lm_head = CastedLinear(self.hidden_size, vocab_size, bias=False)\n",
    "        self.q_head = CastedLinear(self.hidden_size, 1, bias=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.q_head.weight.zero_()\n",
    "            if self.q_head.bias is not None:\n",
    "                self.q_head.bias.fill_(-5.0)\n",
    "\n",
    "        self.carry = None\n",
    "\n",
    "        self.z_H_init = nn.Buffer(\n",
    "            trunc_normal_init_(torch.empty(self.hidden_size, dtype=self.forward_dtype), std=1),\n",
    "            persistent=True,\n",
    "        )\n",
    "        self.z_L_init = nn.Buffer(\n",
    "            trunc_normal_init_(torch.empty(self.hidden_size, dtype=self.forward_dtype), std=1),\n",
    "            persistent=True,\n",
    "        )\n",
    "\n",
    "        # Add puzzle embeddings\n",
    "        if puzzle_emb_dim > 0:\n",
    "            self.puzzle_emb = CastedSparseEmbedding(\n",
    "                num_embeddings=num_puzzles,\n",
    "                embedding_dim=puzzle_emb_dim,\n",
    "                batch_size=batch_size,\n",
    "                init_std=0.0,  # Reference uses 0 init\n",
    "                cast_to=self.forward_dtype,\n",
    "            )\n",
    "            self.puzzle_emb_len = puzzle_emb_len\n",
    "            log.info(f\"Created puzzle_emb with num_puzzles={num_puzzles}, batch_size={batch_size}\")\n",
    "            log.info(f\"puzzle_emb.local_weights.shape: {self.puzzle_emb.local_weights.shape}\")\n",
    "            log.info(f\"puzzle_emb.weights.shape: {self.puzzle_emb.weights.shape}\")\n",
    "        else:\n",
    "            log.info(\"puzzle_emb_dim <= 0, not creating puzzle embeddings\")\n",
    "            self.puzzle_emb = None\n",
    "            self.puzzle_emb_len = 0\n",
    "\n",
    "    def _input_embeddings(self, input: torch.Tensor, puzzle_identifiers: torch.Tensor):\n",
    "        # Token embedding\n",
    "        embedding = self.input_embedding(input.to(torch.int32))\n",
    "\n",
    "        # Puzzle embeddings (Optional, based on your init)\n",
    "        if self.puzzle_emb is not None:\n",
    "            puzzle_embedding = self.puzzle_emb(puzzle_identifiers)\n",
    "            pad_count = self.puzzle_emb_len * self.hidden_size - puzzle_embedding.shape[-1]\n",
    "            if pad_count > 0:\n",
    "                puzzle_embedding = F.pad(puzzle_embedding, (0, pad_count))\n",
    "            \n",
    "            embedding = torch.cat(\n",
    "                (puzzle_embedding.view(-1, self.puzzle_emb_len, self.hidden_size), embedding),\n",
    "                dim=-2,\n",
    "            )\n",
    "\n",
    "        return self.embed_scale * embedding\n",
    "\n",
    "    def inner_forward(self, carry: TRMInnerCarry, batch: Dict[str, torch.Tensor]):\n",
    "        \"\"\"The core recurrent block: processes H_cycles and L_cycles.\"\"\"\n",
    "        \n",
    "        # Calculate Rotary Embeddings if available\n",
    "        seq_info = dict(\n",
    "            cos_sin=self.pos_embedding() if hasattr(self, \"pos_embedding\") else None,\n",
    "        )\n",
    "\n",
    "        input_embeddings = self._input_embeddings(batch[\"input\"], batch[\"puzzle_identifiers\"])\n",
    "\n",
    "        z_H, z_L = carry.z_H, carry.z_L\n",
    "        \n",
    "        # H_cycles: High-level reasoning\n",
    "        # We run H-1 cycles without gradients to save memory (standard TRM trick)\n",
    "        H_cycles = 3 # Default from your config\n",
    "        L_cycles = 6 # Default from your config\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(H_cycles - 1):\n",
    "                for _ in range(L_cycles):\n",
    "                    z_L = self.lenet(z_L, z_H + input_embeddings, **seq_info)\n",
    "                z_H = self.lenet(z_H, z_L, **seq_info)\n",
    "                \n",
    "        # The final cycle tracks gradients\n",
    "        for _ in range(L_cycles):\n",
    "            z_L = self.lenet(z_L, z_H + input_embeddings, **seq_info)\n",
    "        z_H = self.lenet(z_H, z_L, **seq_info)\n",
    "\n",
    "        # Output Heads\n",
    "        new_carry = TRMInnerCarry(z_H=z_H.detach(), z_L=z_L.detach())\n",
    "        \n",
    "        # Slicing off the puzzle embedding tokens to get just the grid predictions\n",
    "        output = self.lm_head(z_H)[:, self.puzzle_emb_len :] \n",
    "        q_logits = self.q_head(z_H[:, 0]).to(torch.float32)\n",
    "\n",
    "        return new_carry, output, q_logits[..., 0]\n",
    "\n",
    "    def initial_carry(self, batch_size, device):\n",
    "        \"\"\"Creates the initial zero-state carry.\"\"\"\n",
    "        return TRMInnerCarry(\n",
    "            z_H=torch.zeros(batch_size, self.seq_len + self.puzzle_emb_len, self.hidden_size, device=device, dtype=self.forward_dtype),\n",
    "            z_L=torch.zeros(batch_size, self.seq_len + self.puzzle_emb_len, self.hidden_size, device=device, dtype=self.forward_dtype),\n",
    "        )\n",
    "\n",
    "    def forward(self, carry: TRMCarry, batch: Dict[str, torch.Tensor], n_supervision: int):\n",
    "        \"\"\"\n",
    "        Runs one step of reasoning.\n",
    "        Logic: \n",
    "        1. If a sample in the batch is 'halted' (finished), reset its state (start over).\n",
    "        2. Run inner_forward.\n",
    "        3. Determine if we should halt now (based on steps or Q-head).\n",
    "        \"\"\"\n",
    "        batch_size = batch[\"input\"].shape[0]\n",
    "        device = batch[\"input\"].device\n",
    "\n",
    "        # If carry is None, initialize it (Start of a new batch)\n",
    "        if carry is None:\n",
    "            inner = self.initial_carry(batch_size, device)\n",
    "            carry = TRMCarry(\n",
    "                inner_carry=inner,\n",
    "                steps=torch.zeros((batch_size,), dtype=torch.int32, device=device),\n",
    "                halted=torch.ones((batch_size,), dtype=torch.bool, device=device), # Start as halted so we reset immediately\n",
    "                current_data=batch\n",
    "            )\n",
    "\n",
    "        # Reset logic: If a sequence halted in the *previous* step, reset it now to start fresh\n",
    "        # Note: We use z_H_init buffer from your init\n",
    "        reset_mask = carry.halted.view(-1, 1, 1)\n",
    "        new_z_H = torch.where(reset_mask, self.z_H_init, carry.inner_carry.z_H)\n",
    "        new_z_L = torch.where(reset_mask, self.z_L_init, carry.inner_carry.z_L)\n",
    "        \n",
    "        new_inner_carry = TRMInnerCarry(z_H=new_z_H, z_L=new_z_L)\n",
    "        new_steps = torch.where(carry.halted, 0, carry.steps)\n",
    "        \n",
    "        # Actual Forward Pass\n",
    "        new_inner_carry, logits, q_halt_logits = self.inner_forward(new_inner_carry, batch)\n",
    "\n",
    "        # Increment steps\n",
    "        new_steps = new_steps + 1\n",
    "        \n",
    "        # Halt Logic (Did we reach max supervision steps?)\n",
    "        # In a simple notebook version, we mostly rely on fixed N steps\n",
    "        halted = new_steps >= n_supervision\n",
    "        \n",
    "        # Update Carry\n",
    "        new_carry = TRMCarry(\n",
    "            inner_carry=new_inner_carry,\n",
    "            steps=new_steps,\n",
    "            halted=halted,\n",
    "            current_data=batch\n",
    "        )\n",
    "\n",
    "        return new_carry, logits, q_halt_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be681401",
   "metadata": {},
   "source": [
    "## Prepare Sudoku dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e769a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Ready: 6x6 Sudoku\n",
      "Vocab Size: 9, Sequence Length: 64\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the DataModule in Generation Mode (data_dir=None)\n",
    "grid_size = 6\n",
    "dm = SudokuDataModule(\n",
    "    data_dir=None,       \n",
    "    batch_size=32,       \n",
    "    num_train_puzzles=1000,\n",
    "    num_val_puzzles=100,\n",
    "    num_test_puzzles=100,\n",
    "    grid_size=grid_size,\n",
    "    num_workers=0  \n",
    ")\n",
    "\n",
    "# 2. Setup the data (generates the puzzle pool)\n",
    "dm.setup()\n",
    "\n",
    "# 3. specific loaders \n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "\n",
    "# 4. Extract metadata needed for the Model dimensions\n",
    "# In generation mode, these are calculated based on grid_size\n",
    "vocab_size = dm.vocab_size \n",
    "seq_len = dm.seq_len\n",
    "puzzle_emb_len = 16 # how many tokes for puzzle embedding\n",
    "\n",
    "print(f\"Data Ready: {grid_size}x{grid_size} Sudoku\")\n",
    "print(f\"Vocab Size: {vocab_size}, Sequence Length: {seq_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ac373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 17, Empty: 19\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 3 7 . | . . . |\n",
      "| 6 . . | 4 . . |\n",
      "+-------+-------+\n",
      "| 2 . . | 6 . 7 |\n",
      "| . . 6 | 3 8 . |\n",
      "+-------+-------+\n",
      "| 8 3 . | . 6 . |\n",
      "| 4 . 2 | 7 3 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 3 7 4 | 8 2 6 |\n",
      "| 6 2 8 | 4 7 3 |\n",
      "+-------+-------+\n",
      "| 2 8 3 | 6 4 7 |\n",
      "| 7 4 6 | 3 8 2 |\n",
      "+-------+-------+\n",
      "| 8 3 7 | 2 6 4 |\n",
      "| 4 6 2 | 7 3 8 |\n",
      "+-------+-------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "# Visualize the first element in the batch\n",
    "visualize_sudoku_text(batch, idx=0, grid_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b25c82",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061b6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(batch, logits, grid_size=4):\n",
    "    \"\"\"Visualizes the first sample in the batch: Input vs Prediction vs Target\"\"\"\n",
    "    inputs = batch['input'][0].cpu().numpy()\n",
    "    targets = batch['output'][0].cpu().numpy()\n",
    "    preds = logits[0].argmax(dim=-1).cpu().numpy()\n",
    "    \n",
    "    # Remap tokens back to numbers (0=pad, 1=eos, 2=empty, 3+=values)\n",
    "    # See pad_and_encode in SudokuDataset\n",
    "    def decode(flat_arr):\n",
    "        arr = flat_arr[:grid_size*grid_size].reshape(grid_size, grid_size)\n",
    "        # Shift back: 2->0 (empty), 3->1 (val 1)\n",
    "        res = np.zeros_like(arr)\n",
    "        mask = arr >= 3\n",
    "        res[mask] = arr[mask] - 2\n",
    "        return res\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "    titles = [\"Input (0=Empty)\", \"Prediction\", \"Target\"]\n",
    "    for ax, data, title in zip(axes, [inputs, preds, targets], titles):\n",
    "        grid = decode(data)\n",
    "        ax.matshow(grid, cmap='Blues')\n",
    "        for (i, j), z in np.ndenumerate(grid):\n",
    "            ax.text(j, i, f'{z}', ha='center', va='center', \n",
    "                    color='black' if z != 0 else 'lightgray')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69199f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TRM Model...\n",
      "----------------------------------------\n",
      "Model successfully initialized on cuda\n",
      "Parameters: 4.83M\n",
      "Configuration: MLP_T=True, PosEmb=None\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"grid_size\": 6,             \n",
    "    \"batch_size\": 32,\n",
    "    \"max_epochs\": 1000,\n",
    "    \"hidden_size\": 512,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_heads\": 8,\n",
    "    \"ffn_expansion\": 4,\n",
    "    \"puzzle_emb_dim\": 0,        \n",
    "    \"puzzle_emb_len\": 0,        \n",
    "    \"pos_emb_type\": None,       \n",
    "    \"use_mlp_t\": True,          \n",
    "    \"use_conv_swiglu\": False,\n",
    "    \"use_board_swiglu\": False,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1.0,\n",
    "    \"N_supervision\": 16\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Initializing TRM Model...\")\n",
    "\n",
    "model = TRMModel(\n",
    "    vocab_size=3 + dm.max_grid_size,  # 0=PAD, 1=EOS, 2=Empty, 3+=Values\n",
    "    seq_len=dm.seq_len,\n",
    "    max_grid_size=dm.max_grid_size,\n",
    "    pad_value=0,\n",
    "    hidden_size=CONFIG[\"hidden_size\"],\n",
    "    num_layers=CONFIG[\"num_layers\"],\n",
    "    num_heads=CONFIG[\"num_heads\"],\n",
    "    ffn_expansion=CONFIG[\"ffn_expansion\"],\n",
    "    puzzle_emb_dim=CONFIG[\"puzzle_emb_dim\"],\n",
    "    puzzle_emb_len=CONFIG[\"puzzle_emb_len\"],\n",
    "    pos_emb_type=CONFIG[\"pos_emb_type\"],  \n",
    "    use_mlp_t=CONFIG[\"use_mlp_t\"],    \n",
    "    use_conv_swiglu=CONFIG[\"use_conv_swiglu\"],\n",
    "    use_board_swiglu=CONFIG[\"use_board_swiglu\"],\n",
    "    # Dataset specific (required for safeguards even if puzzle_emb_dim=0)\n",
    "    num_puzzles=0,    \n",
    "    batch_size=CONFIG[\"batch_size\"]\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=CONFIG[\"learning_rate\"], \n",
    "    weight_decay=CONFIG[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Model successfully initialized on {device}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "print(f\"Configuration: MLP_T={CONFIG['use_mlp_t']}, PosEmb={CONFIG['pos_emb_type']}\")\n",
    "print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa5806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda...\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 16, Empty: 20\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 3 . 6 | . 2 1 |\n",
      "| . . . | . . . |\n",
      "+-------+-------+\n",
      "| . 6 4 | . 1 . |\n",
      "| . 1 . | 5 6 . |\n",
      "+-------+-------+\n",
      "| . 4 . | 1 3 . |\n",
      "| 1 . . | 6 . 2 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 3 5 6 | 4 2 1 |\n",
      "| 4 2 1 | 3 5 6 |\n",
      "+-------+-------+\n",
      "| 5 6 4 | 2 1 3 |\n",
      "| 2 1 3 | 5 6 4 |\n",
      "+-------+-------+\n",
      "| 6 4 2 | 1 3 5 |\n",
      "| 1 3 5 | 6 4 2 |\n",
      "+-------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 17, Empty: 19\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 6 5 . | . 3 1 |\n",
      "| . 3 . | . . . |\n",
      "+-------+-------+\n",
      "| . . . | 3 . 6 |\n",
      "| 3 . 6 | 5 2 . |\n",
      "+-------+-------+\n",
      "| . . . | . 6 5 |\n",
      "| . 6 5 | 2 7 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 6 5 2 | 7 3 1 |\n",
      "| 7 3 1 | 6 5 2 |\n",
      "+-------+-------+\n",
      "| 5 2 7 | 3 1 6 |\n",
      "| 3 1 6 | 5 2 7 |\n",
      "+-------+-------+\n",
      "| 2 7 3 | 1 6 5 |\n",
      "| 1 6 5 | 2 7 3 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 19, Empty: 17\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 5 . . | 2 3 6 |\n",
      "| 2 . . | . . 1 |\n",
      "+-------+-------+\n",
      "| 8 . . | 3 . 2 |\n",
      "| . 1 2 | . 6 5 |\n",
      "+-------+-------+\n",
      "| 1 . . | 6 2 . |\n",
      "| . 2 . | 1 5 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 5 8 1 | 2 3 6 |\n",
      "| 2 3 6 | 5 8 1 |\n",
      "+-------+-------+\n",
      "| 8 6 5 | 3 1 2 |\n",
      "| 3 1 2 | 8 6 5 |\n",
      "+-------+-------+\n",
      "| 1 5 3 | 6 2 8 |\n",
      "| 6 2 8 | 1 5 3 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 20, Empty: 16\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 1 . 3 | . 8 . |\n",
      "| . . 7 | 6 1 3 |\n",
      "+-------+-------+\n",
      "| 6 . . | . . . |\n",
      "| 2 3 . | . 6 8 |\n",
      "+-------+-------+\n",
      "| . 8 . | 1 7 2 |\n",
      "| 7 1 2 | . . 6 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 1 6 3 | 2 8 7 |\n",
      "| 8 2 7 | 6 1 3 |\n",
      "+-------+-------+\n",
      "| 6 7 8 | 3 2 1 |\n",
      "| 2 3 1 | 7 6 8 |\n",
      "+-------+-------+\n",
      "| 3 8 6 | 1 7 2 |\n",
      "| 7 1 2 | 8 3 6 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 15, Empty: 21\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . . 7 | 5 . . |\n",
      "| . . . | . . 2 |\n",
      "+-------+-------+\n",
      "| . 6 . | 4 . . |\n",
      "| 4 . . | 2 5 . |\n",
      "+-------+-------+\n",
      "| . 8 . | . 2 . |\n",
      "| . 5 2 | 6 4 8 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 8 2 7 | 5 6 4 |\n",
      "| 5 4 6 | 8 7 2 |\n",
      "+-------+-------+\n",
      "| 2 6 5 | 4 8 7 |\n",
      "| 4 7 8 | 2 5 6 |\n",
      "+-------+-------+\n",
      "| 6 8 4 | 7 2 5 |\n",
      "| 7 5 2 | 6 4 8 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 12, Empty: 24\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 4 . . | . . . |\n",
      "| . 1 8 | . . . |\n",
      "+-------+-------+\n",
      "| 8 . 5 | . 1 . |\n",
      "| . . 1 | . 5 . |\n",
      "+-------+-------+\n",
      "| . 8 . | 6 7 . |\n",
      "| . . . | . . 1 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 4 5 6 | 1 8 7 |\n",
      "| 7 1 8 | 5 6 4 |\n",
      "+-------+-------+\n",
      "| 8 4 5 | 7 1 6 |\n",
      "| 6 7 1 | 4 5 8 |\n",
      "+-------+-------+\n",
      "| 1 8 4 | 6 7 5 |\n",
      "| 5 6 7 | 8 4 1 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 19, Empty: 17\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 5 . . | 4 . . |\n",
      "| . 1 7 | . . 8 |\n",
      "+-------+-------+\n",
      "| . 5 8 | 6 1 . |\n",
      "| 6 4 . | . 8 . |\n",
      "+-------+-------+\n",
      "| . 7 . | 8 . 6 |\n",
      "| 8 . . | 1 5 7 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 5 8 6 | 4 7 1 |\n",
      "| 4 1 7 | 5 6 8 |\n",
      "+-------+-------+\n",
      "| 7 5 8 | 6 1 4 |\n",
      "| 6 4 1 | 7 8 5 |\n",
      "+-------+-------+\n",
      "| 1 7 5 | 8 4 6 |\n",
      "| 8 6 4 | 1 5 7 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 15, Empty: 21\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . 4 . | 6 . . |\n",
      "| 6 . 8 | . 4 3 |\n",
      "+-------+-------+\n",
      "| . . . | . 2 . |\n",
      "| 3 2 5 | . . 4 |\n",
      "+-------+-------+\n",
      "| 5 3 . | . . 2 |\n",
      "| . . . | . 3 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 2 4 3 | 6 5 8 |\n",
      "| 6 5 8 | 2 4 3 |\n",
      "+-------+-------+\n",
      "| 8 6 4 | 3 2 5 |\n",
      "| 3 2 5 | 8 6 4 |\n",
      "+-------+-------+\n",
      "| 5 3 6 | 4 8 2 |\n",
      "| 4 8 2 | 5 3 6 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 12, Empty: 24\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . 5 2 | . 7 . |\n",
      "| 6 . . | . . 2 |\n",
      "+-------+-------+\n",
      "| . . 5 | . 1 . |\n",
      "| . . . | . 6 5 |\n",
      "+-------+-------+\n",
      "| . . . | . 8 1 |\n",
      "| . . . | 7 . . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 1 5 2 | 6 7 8 |\n",
      "| 6 7 8 | 1 5 2 |\n",
      "+-------+-------+\n",
      "| 8 6 5 | 2 1 7 |\n",
      "| 2 1 7 | 8 6 5 |\n",
      "+-------+-------+\n",
      "| 7 2 6 | 5 8 1 |\n",
      "| 5 8 1 | 7 2 6 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 13, Empty: 23\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 7 . . | 1 . . |\n",
      "| . . 5 | 7 . . |\n",
      "+-------+-------+\n",
      "| . . . | 8 7 5 |\n",
      "| . 5 . | . . . |\n",
      "+-------+-------+\n",
      "| . 7 . | . 8 1 |\n",
      "| 3 . . | . 2 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 7 2 3 | 1 5 8 |\n",
      "| 1 8 5 | 7 3 2 |\n",
      "+-------+-------+\n",
      "| 2 3 1 | 8 7 5 |\n",
      "| 8 5 7 | 2 1 3 |\n",
      "+-------+-------+\n",
      "| 5 7 2 | 3 8 1 |\n",
      "| 3 1 8 | 5 2 7 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 17, Empty: 19\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . 6 . | 2 . . |\n",
      "| 2 7 1 | . 6 . |\n",
      "+-------+-------+\n",
      "| . 5 7 | 1 . . |\n",
      "| . 2 . | 4 . 7 |\n",
      "+-------+-------+\n",
      "| . 1 . | 7 . . |\n",
      "| 7 4 . | 6 . . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 5 6 4 | 2 7 1 |\n",
      "| 2 7 1 | 5 6 4 |\n",
      "+-------+-------+\n",
      "| 4 5 7 | 1 2 6 |\n",
      "| 1 2 6 | 4 5 7 |\n",
      "+-------+-------+\n",
      "| 6 1 5 | 7 4 2 |\n",
      "| 7 4 2 | 6 1 5 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 20, Empty: 16\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 6 . . | 5 . 3 |\n",
      "| . 5 . | 8 6 . |\n",
      "+-------+-------+\n",
      "| 3 . . | 6 . 5 |\n",
      "| 1 6 . | 7 3 . |\n",
      "+-------+-------+\n",
      "| 5 1 7 | 3 . 6 |\n",
      "| 8 . 6 | . . . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 6 8 1 | 5 7 3 |\n",
      "| 7 5 3 | 8 6 1 |\n",
      "+-------+-------+\n",
      "| 3 7 8 | 6 1 5 |\n",
      "| 1 6 5 | 7 3 8 |\n",
      "+-------+-------+\n",
      "| 5 1 7 | 3 8 6 |\n",
      "| 8 3 6 | 1 5 7 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 13, Empty: 23\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . . 2 | 5 . . |\n",
      "| . . . | . . . |\n",
      "+-------+-------+\n",
      "| . 3 4 | 2 . . |\n",
      "| 5 2 . | . . 6 |\n",
      "+-------+-------+\n",
      "| 3 1 6 | . . . |\n",
      "| 2 . . | . . 3 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 4 6 2 | 5 3 1 |\n",
      "| 1 5 3 | 6 2 4 |\n",
      "+-------+-------+\n",
      "| 6 3 4 | 2 1 5 |\n",
      "| 5 2 1 | 3 4 6 |\n",
      "+-------+-------+\n",
      "| 3 1 6 | 4 5 2 |\n",
      "| 2 4 5 | 1 6 3 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 17, Empty: 19\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 7 4 3 | . . . |\n",
      "| 5 . . | 3 . 7 |\n",
      "+-------+-------+\n",
      "| . 5 4 | 2 . . |\n",
      "| . . . | . . . |\n",
      "+-------+-------+\n",
      "| 2 3 5 | . 6 . |\n",
      "| . 6 7 | 5 3 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 7 4 3 | 6 2 5 |\n",
      "| 5 2 6 | 3 4 7 |\n",
      "+-------+-------+\n",
      "| 6 5 4 | 2 7 3 |\n",
      "| 3 7 2 | 4 5 6 |\n",
      "+-------+-------+\n",
      "| 2 3 5 | 7 6 4 |\n",
      "| 4 6 7 | 5 3 2 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 14, Empty: 22\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 8 . . | 1 . . |\n",
      "| . . . | 3 . . |\n",
      "+-------+-------+\n",
      "| . 1 . | . 5 3 |\n",
      "| 5 . . | 7 . 1 |\n",
      "+-------+-------+\n",
      "| 1 8 . | . . . |\n",
      "| 3 7 6 | . . . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 8 6 3 | 1 7 5 |\n",
      "| 7 5 1 | 3 8 6 |\n",
      "+-------+-------+\n",
      "| 6 1 7 | 8 5 3 |\n",
      "| 5 3 8 | 7 6 1 |\n",
      "+-------+-------+\n",
      "| 1 8 5 | 6 3 7 |\n",
      "| 3 7 6 | 5 1 8 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 19, Empty: 17\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . . . | . 6 . |\n",
      "| 8 5 6 | 1 7 . |\n",
      "+-------+-------+\n",
      "| . 7 8 | . . . |\n",
      "| 5 . 1 | . 8 7 |\n",
      "+-------+-------+\n",
      "| . 1 . | 7 . . |\n",
      "| 7 . 5 | 6 2 1 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 1 2 7 | 8 6 5 |\n",
      "| 8 5 6 | 1 7 2 |\n",
      "+-------+-------+\n",
      "| 2 7 8 | 5 1 6 |\n",
      "| 5 6 1 | 2 8 7 |\n",
      "+-------+-------+\n",
      "| 6 1 2 | 7 5 8 |\n",
      "| 7 8 5 | 6 2 1 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 20, Empty: 16\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 1 4 7 | 6 5 2 |\n",
      "| . 5 . | . . . |\n",
      "+-------+-------+\n",
      "| 7 . 4 | . 1 . |\n",
      "| 6 1 5 | . . 7 |\n",
      "+-------+-------+\n",
      "| . . . | 1 . 5 |\n",
      "| 5 7 1 | . . 4 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 1 4 7 | 6 5 2 |\n",
      "| 2 5 6 | 7 4 1 |\n",
      "+-------+-------+\n",
      "| 7 2 4 | 5 1 6 |\n",
      "| 6 1 5 | 4 2 7 |\n",
      "+-------+-------+\n",
      "| 4 6 2 | 1 7 5 |\n",
      "| 5 7 1 | 2 6 4 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 12, Empty: 24\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . . 4 | . . . |\n",
      "| 6 3 7 | . . 8 |\n",
      "+-------+-------+\n",
      "| . 4 . | 8 2 . |\n",
      "| . . . | . . 4 |\n",
      "+-------+-------+\n",
      "| . . . | 4 . . |\n",
      "| . . . | 7 . 6 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 2 8 4 | 6 7 3 |\n",
      "| 6 3 7 | 2 4 8 |\n",
      "+-------+-------+\n",
      "| 3 4 6 | 8 2 7 |\n",
      "| 8 7 2 | 3 6 4 |\n",
      "+-------+-------+\n",
      "| 7 6 8 | 4 3 2 |\n",
      "| 4 2 3 | 7 8 6 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 17, Empty: 19\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . . 3 | 2 . . |\n",
      "| 2 . . | 6 3 . |\n",
      "+-------+-------+\n",
      "| . 6 4 | . . 2 |\n",
      "| . 2 . | 8 4 6 |\n",
      "+-------+-------+\n",
      "| 1 . 2 | . . 3 |\n",
      "| . 3 . | . . 8 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 6 1 3 | 2 8 4 |\n",
      "| 2 4 8 | 6 3 1 |\n",
      "+-------+-------+\n",
      "| 8 6 4 | 3 1 2 |\n",
      "| 3 2 1 | 8 4 6 |\n",
      "+-------+-------+\n",
      "| 1 8 2 | 4 6 3 |\n",
      "| 4 3 6 | 1 2 8 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 16, Empty: 20\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 2 . 5 | . 8 7 |\n",
      "| . . . | . . 2 |\n",
      "+-------+-------+\n",
      "| . 5 . | 8 . 3 |\n",
      "| . . 2 | . 7 . |\n",
      "+-------+-------+\n",
      "| 5 . 4 | 7 3 . |\n",
      "| . 7 . | . 4 . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 2 3 5 | 4 8 7 |\n",
      "| 7 4 8 | 3 5 2 |\n",
      "+-------+-------+\n",
      "| 4 5 7 | 8 2 3 |\n",
      "| 3 8 2 | 5 7 4 |\n",
      "+-------+-------+\n",
      "| 5 2 4 | 7 3 8 |\n",
      "| 8 7 3 | 2 4 5 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 21, Empty: 15\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 5 3 . | 4 . . |\n",
      "| . 2 4 | 6 . . |\n",
      "+-------+-------+\n",
      "| 2 4 . | 1 . . |\n",
      "| 3 6 . | 5 4 2 |\n",
      "+-------+-------+\n",
      "| 6 . . | 3 5 . |\n",
      "| 4 . 3 | . 1 6 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 5 3 6 | 4 2 1 |\n",
      "| 1 2 4 | 6 3 5 |\n",
      "+-------+-------+\n",
      "| 2 4 5 | 1 6 3 |\n",
      "| 3 6 1 | 5 4 2 |\n",
      "+-------+-------+\n",
      "| 6 1 2 | 3 5 4 |\n",
      "| 4 5 3 | 2 1 6 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 21, Empty: 15\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 3 4 8 | . 1 . |\n",
      "| 6 . . | . 8 3 |\n",
      "+-------+-------+\n",
      "| 8 . . | . 7 . |\n",
      "| 1 3 7 | 6 4 8 |\n",
      "+-------+-------+\n",
      "| . . . | 8 3 . |\n",
      "| . . 3 | 1 6 4 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 3 4 8 | 7 1 6 |\n",
      "| 6 7 1 | 4 8 3 |\n",
      "+-------+-------+\n",
      "| 8 6 4 | 3 7 1 |\n",
      "| 1 3 7 | 6 4 8 |\n",
      "+-------+-------+\n",
      "| 4 1 6 | 8 3 7 |\n",
      "| 7 8 3 | 1 6 4 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 19, Empty: 17\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 2 8 3 | . 6 7 |\n",
      "| . . . | . . . |\n",
      "+-------+-------+\n",
      "| . 6 8 | 7 . . |\n",
      "| . 2 7 | 8 . 6 |\n",
      "+-------+-------+\n",
      "| 7 3 6 | 2 . . |\n",
      "| . 5 2 | 6 . . |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 2 8 3 | 5 6 7 |\n",
      "| 6 7 5 | 3 2 8 |\n",
      "+-------+-------+\n",
      "| 5 6 8 | 7 3 2 |\n",
      "| 3 2 7 | 8 5 6 |\n",
      "+-------+-------+\n",
      "| 7 3 6 | 2 8 5 |\n",
      "| 8 5 2 | 6 7 3 |\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 19, Empty: 17\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| 6 1 . | . . . |\n",
      "| . 3 . | . 6 2 |\n",
      "+-------+-------+\n",
      "| . . 8 | . 3 . |\n",
      "| . 7 6 | 2 . . |\n",
      "+-------+-------+\n",
      "| 2 8 3 | . 7 1 |\n",
      "| 7 6 . | 8 . 3 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 6 1 2 | 3 8 7 |\n",
      "| 8 3 7 | 1 6 2 |\n",
      "+-------+-------+\n",
      "| 1 2 8 | 7 3 6 |\n",
      "| 3 7 6 | 2 1 8 |\n",
      "+-------+-------+\n",
      "| 2 8 3 | 6 7 1 |\n",
      "| 7 6 1 | 8 2 3 |\n",
      "+-------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     75\u001b[39m loss = lm_loss + \u001b[32m0.5\u001b[39m * q_halt_loss\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     80\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(f\"Starting training on {device}...\")\n",
    "EPOCHS = 3\n",
    "N_SUPERVISION = 4\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        visualize_sudoku_text(batch, idx=0, grid_size=6)\n",
    "        # 1. Initialize State for this new batch\n",
    "        carry = None \n",
    "        \n",
    "        # 2. Reasoning Loop (The \"Recurrent\" part of TRM)\n",
    "        # We process the SAME batch multiple times (N_SUPERVISION)\n",
    "        # allowing the model to refine its hidden state\n",
    "        for step in range(N_SUPERVISION):\n",
    "            optimizer.zero_grad()\n",
    "            # 1. Forward pass\n",
    "            carry, logits, q_logits = model(carry, batch, n_supervision=N_SUPERVISION)\n",
    "            \n",
    "            labels = batch['output']\n",
    "            \n",
    "            # ---------------------------------------------------------\n",
    "            # Loss 1: Language Modeling (Sudoku Solution)\n",
    "            # ---------------------------------------------------------\n",
    "            # Flatten for CrossEntropy: [batch * seq_len, vocab_size]\n",
    "            flat_logits = logits.reshape(-1, logits.shape[-1])\n",
    "            flat_labels = labels.reshape(-1)\n",
    "\n",
    "            lm_loss = F.cross_entropy(\n",
    "                flat_logits, \n",
    "                flat_labels, \n",
    "                ignore_index=-100 \n",
    "            )\n",
    "\n",
    "            # ---------------------------------------------------------\n",
    "            # Loss 2: Halting (Q-Head)\n",
    "            # ---------------------------------------------------------\n",
    "            # We need to determine if the model *actually* got the solution right \n",
    "            # for this specific step. The target for the Q-head is 1.0 if correct, 0.0 otherwise.\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Get predictions\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                \n",
    "                # Mask out padding/ignore tokens (-100)\n",
    "                mask = labels != -100\n",
    "                \n",
    "                # Check correctness per cell\n",
    "                # (Where mask is True, pred must match label)\n",
    "                correct_cells = (preds == labels) & mask\n",
    "                \n",
    "                # Count required correct cells per sequence\n",
    "                required_correct = mask.sum(dim=-1)\n",
    "                \n",
    "                # Count actual correct cells per sequence\n",
    "                actual_correct = correct_cells.sum(dim=-1)\n",
    "                \n",
    "                # A sequence is correct ONLY if all non-ignored tokens match\n",
    "                seq_is_correct = (actual_correct == required_correct).float()\n",
    "\n",
    "            # Binary Cross Entropy for the halting head\n",
    "            # q_logits shape: [batch_size] -> We need to align with seq_is_correct\n",
    "            q_halt_loss = F.binary_cross_entropy_with_logits(\n",
    "                q_logits, \n",
    "                seq_is_correct.to(q_logits.device)\n",
    "            )\n",
    "\n",
    "            # ---------------------------------------------------------\n",
    "            # Total Loss\n",
    "            # ---------------------------------------------------------\n",
    "            # Standard TRM weighting: 1.0 * LM + 0.5 * Q_Halt\n",
    "            loss = lm_loss + 0.5 * q_halt_loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Detach carry to prevent infinite graph growth\n",
    "            if carry is not None:\n",
    "                carry.inner_carry.z_H = carry.inner_carry.z_H.detach()\n",
    "                carry.inner_carry.z_L = carry.inner_carry.z_L.detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-trm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

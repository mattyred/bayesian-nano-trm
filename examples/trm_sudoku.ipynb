{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805491e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict, Union, Any\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.nn.modules.utils import compute_lr\n",
    "from src.nn.utils.constants import IGNORE_LABEL_ID\n",
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "from src.nn.modules.utils import trunc_normal_init_\n",
    "from src.nn.data.sudoku_datamodule import SudokuDataModule\n",
    "\n",
    "from src.nn.modules.utils import stablemax_cross_entropy, trunc_normal_init_\n",
    "from src.nn.utils import RankedLogger\n",
    "\n",
    "from examples.utils import visualize_sudoku_text\n",
    "\n",
    "CosSin = Tuple[torch.Tensor, torch.Tensor]\n",
    "log = RankedLogger(__name__, rank_zero_only=True)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "# set seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdaa610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CastedLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool):\n",
    "        super().__init__()\n",
    "        # Truncated LeCun normal init\n",
    "        self.weight = nn.Parameter(\n",
    "            trunc_normal_init_(\n",
    "                torch.empty((out_features, in_features)), std=1.0 / (in_features**0.5)\n",
    "            )\n",
    "        )\n",
    "        self.bias = None\n",
    "        if bias:\n",
    "            # Zero init bias\n",
    "            self.bias = nn.Parameter(torch.zeros((out_features,)))\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(\n",
    "            input,\n",
    "            self.weight.to(input.dtype),\n",
    "            bias=self.bias.to(input.dtype) if self.bias is not None else None,\n",
    "        )\n",
    "    \n",
    "class CastedEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_embeddings: int, embedding_dim: int, init_std: float, cast_to: torch.dtype\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cast_to = cast_to\n",
    "\n",
    "        # Truncated LeCun normal init\n",
    "        self.embedding_weight = nn.Parameter(\n",
    "            trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return F.embedding(input, self.embedding_weight.to(self.cast_to))\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, hidden_size: int, expansion: float):\n",
    "        super().__init__()\n",
    "        inter = _find_multiple(round(expansion * hidden_size * 2 / 3), 256)\n",
    "\n",
    "        self.gate_up_proj = CastedLinear(hidden_size, inter * 2, bias=False)\n",
    "        self.down_proj = CastedLinear(inter, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, up = self.gate_up_proj(x).chunk(2, dim=-1)\n",
    "        return self.down_proj(F.silu(gate) * up)\n",
    "\n",
    "def rms_norm(hidden_states: torch.Tensor, variance_epsilon: float) -> torch.Tensor:\n",
    "    input_dtype = hidden_states.dtype\n",
    "    hidden_states = hidden_states.to(torch.float32)\n",
    "\n",
    "    variance = hidden_states.square().mean(-1, keepdim=True)\n",
    "    hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
    "    return hidden_states.to(input_dtype)\n",
    "\n",
    "def _find_multiple(a, b):\n",
    "    return (-(a // -b)) * b\n",
    "\n",
    "class ReasoningBlockConfig:\n",
    "    \"\"\"\n",
    "    Configuration A: The \"Standard Transformer\"\n",
    "        mlp_t=False (Use Attention)\n",
    "        use_convswiglu/use_boardswiglu=False (Use Standard MLP)\n",
    "        Result: Classic powerful reasoning. Attention handles global context; MLP handles logic.\n",
    "\n",
    "    Configuration B: The \"Spatial-Inductive Transformer\"\n",
    "        mlp_t=False (Use Attention)\n",
    "        use_convswiglu/use_boardswiglu=True (Use Conv MLP)\n",
    "        Result: Strongest. Attention sees the whole board (\"I can win in column 7\"), while ConvSwiGLU recognizes patterns immediately (\"I have 3-in-a-row here\"). This gives the best of both worlds.\n",
    "\n",
    "    Configuration C: The \"MLP-Mixer\" (Pure MLP)\n",
    "        mlp_t=True (Use Token MLP)\n",
    "        use_convswiglu/use_boardswiglu=False (Use Standard MLP)\n",
    "        Result: Very fast, very stable, but no Attention. The model mixes information globally using a fixed matrix. It might struggle with \"dynamic\" reasoning.\n",
    "\n",
    "    Configuration D: The \"ConvMixer\"\n",
    "        mlp_t=True\n",
    "        use_convswiglu/use_boardswiglu=True\n",
    "        Result: A fully convolutional/MLP network. It has zero attention mechanisms: mlp_t mixes the board globally (fixed weights), convswiglu mixes neighbors locally.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        num_heads: int,\n",
    "        expansion: int,\n",
    "        rms_norm_eps: float,\n",
    "        mlp_t: bool = False,\n",
    "        seq_len: int = 0,\n",
    "        cols: int = None,\n",
    "        rows: int = None,\n",
    "        puzzle_emb_ndim: int = 0,\n",
    "        puzzle_emb_len: int = 0,\n",
    "        use_conv_swiglu: bool = False,\n",
    "        use_board_swiglu: bool = False,\n",
    "        dropout: float = 0.1\n",
    "    ) -> None:\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.expansion = expansion\n",
    "        self.rms_norm_eps = rms_norm_eps\n",
    "        self.mlp_t = mlp_t\n",
    "        self.puzzle_emb_ndim = puzzle_emb_ndim\n",
    "        self.puzzle_emb_len = puzzle_emb_len\n",
    "        self.seq_len = seq_len\n",
    "        self.cols = cols\n",
    "        self.rows = rows\n",
    "        self.use_conv_swiglu = use_conv_swiglu\n",
    "        self.use_board_swiglu = use_board_swiglu\n",
    "        self.dropout = dropout\n",
    "\n",
    "class ReasoningBlock(nn.Module):\n",
    "    def __init__(self, config: ReasoningBlockConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.norm_eps = config.rms_norm_eps\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        # 1. Calculate Effective Length\n",
    "        # If config is 0 (auto), infer from dimensions. Otherwise use config.\n",
    "        # This handles the case where puzzle_emb_ndim > 0 but puzzle_emb_len was not manually set.\n",
    "        self.puzzle_emb_len = (\n",
    "            -(config.puzzle_emb_ndim // -config.hidden_size)\n",
    "            if config.puzzle_emb_len == 0\n",
    "            else config.puzzle_emb_len\n",
    "        )\n",
    "\n",
    "        self.mlp_t = SwiGLU(\n",
    "            hidden_size=config.seq_len + self.puzzle_emb_len, \n",
    "            expansion=config.expansion,\n",
    "        )\n",
    "        self.mlp = SwiGLU(\n",
    "            hidden_size=config.hidden_size,\n",
    "            expansion=config.expansion,\n",
    "        )\n",
    "\n",
    "    def forward(self, cos_sin: CosSin, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        if self.config.mlp_t:\n",
    "            hidden_states = hidden_states.transpose(1,2)\n",
    "            out = self.mlp_t(hidden_states)\n",
    "            out = self.dropout(out)\n",
    "            hidden_states = rms_norm(hidden_states + out, variance_epsilon=self.norm_eps)\n",
    "            hidden_states = hidden_states.transpose(1,2)\n",
    "        else:\n",
    "            attn_out = self.self_attn(cos_sin=cos_sin, hidden_states=hidden_states)\n",
    "            hidden_states = rms_norm(hidden_states + attn_out, variance_epsilon=self.norm_eps)\n",
    "\n",
    "        mlp_out = self.mlp(hidden_states)\n",
    "        hidden_states = rms_norm(hidden_states + mlp_out, variance_epsilon=self.norm_eps)\n",
    "            \n",
    "        return hidden_states\n",
    "\n",
    "class ReasoningModule(nn.Module):\n",
    "    def __init__(self, layers: List[ReasoningBlock]):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: torch.Tensor, input_injection: torch.Tensor, **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        hidden_states = hidden_states + input_injection\n",
    "        for layer in self.layers:\n",
    "            hidden_states = layer(hidden_states=hidden_states, **kwargs)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cbd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TRMInnerCarry:\n",
    "    z_H: torch.Tensor  # High-level state (y = the solution representation)\n",
    "    z_L: torch.Tensor  # Low-level state (z = the problem representation)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TRMCarry:\n",
    "    \"\"\"Carry structure for maintaining state across steps.\"\"\"\n",
    "\n",
    "    inner_carry: TRMInnerCarry\n",
    "    steps: torch.Tensor\n",
    "    halted: torch.Tensor\n",
    "    current_data: Dict[str, torch.Tensor]  # Stores current batch data\n",
    "    \n",
    "class TRMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    HRM implementation following Figure 2 pseudocode exactly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 512,\n",
    "        num_layers: int = 2,\n",
    "        num_heads: int = 8,  # min(2, hidden_size // 64)\n",
    "        max_grid_size: int = 30,\n",
    "        H_cycles: int = 3,\n",
    "        L_cycles: int = 6,\n",
    "        N_supervision: int = 16,\n",
    "        N_supervision_val: int = 16,\n",
    "        ffn_expansion: int = 2,\n",
    "        learning_rate: float = 1e-4,\n",
    "        learning_rate_emb: float = 1e-2,\n",
    "        weight_decay: float = 0.01,\n",
    "        warmup_steps: int = 2000,\n",
    "        halt_exploration_prob: float = 0.1,\n",
    "        puzzle_emb_dim: int = 512,  # Puzzle embedding dimension\n",
    "        puzzle_emb_len: int = 16,  # How many tokens for puzzle embedding\n",
    "        rope_theta: int = 10000,\n",
    "        pos_emb_type: str = \"1d\",\n",
    "        use_mlp_t: bool = False,\n",
    "        use_conv_swiglu: bool = False,\n",
    "        use_board_swiglu: bool = False,\n",
    "        lr_min_ratio: float = 1.0,\n",
    "        use_muon: bool = False,\n",
    "        vocab_size: int = 0,  # Should be set from datamodule\n",
    "        num_puzzles: int = 0,  # Should be set from datamodule\n",
    "        batch_size: int = 0,  # Should be set from datamodule\n",
    "        pad_value: int = -1,  # Should be set from datamodule\n",
    "        seq_len: int = 0,  # Should be set from datamodule\n",
    "        output_dir: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.num_heads=num_heads\n",
    "        self.max_grid_size=max_grid_size\n",
    "        self.H_cycles=H_cycles\n",
    "        self.L_cycles=L_cycles\n",
    "        self.N_supervision=N_supervision\n",
    "        self.N_supervision_val=N_supervision_val\n",
    "        self.ffn_expansion=ffn_expansion\n",
    "        self.learning_rate=learning_rate\n",
    "        self.learning_rate_emb=learning_rate_emb\n",
    "        self.weight_decay=weight_decay\n",
    "        self.warmup_steps=warmup_steps\n",
    "        self.halt_exploration_prob=halt_exploration_prob\n",
    "        self.puzzle_emb_dim=puzzle_emb_dim\n",
    "        self.puzzle_emb_len=puzzle_emb_len\n",
    "        self.rope_theta=rope_theta\n",
    "        self.pos_emb_type=pos_emb_type\n",
    "        self.use_mlp_t=use_mlp_t\n",
    "        self.use_conv_swiglu=use_conv_swiglu\n",
    "        self.use_board_swiglu=use_board_swiglu\n",
    "        self.lr_min_ratio=lr_min_ratio\n",
    "        self.use_muon=use_muon\n",
    "        self.vocab_size=vocab_size\n",
    "        self.num_puzzles=num_puzzles\n",
    "        self.batch_size=batch_size\n",
    "        self.pad_value=pad_value\n",
    "        self.seq_len=seq_len\n",
    "        self.output_dir=output_dir\n",
    "        self.forward_dtype = torch.bfloat16\n",
    "\n",
    "        # Token embeddings\n",
    "        self.embed_scale = math.sqrt(hidden_size)\n",
    "        embed_init_std = 1.0 / self.embed_scale\n",
    "\n",
    "        log.info(f\"Creating TRM with vocab size={vocab_size}, seq_len={seq_len}, puzzle_emb_len={puzzle_emb_len} {pos_emb_type=} {puzzle_emb_dim=}\")\n",
    "        log.info(f\"{use_mlp_t=}, {use_conv_swiglu=}, {use_board_swiglu=}\")\n",
    "\n",
    "         # Input embedding\n",
    "        self.input_embedding = CastedEmbedding(\n",
    "            vocab_size, hidden_size, init_std=embed_init_std, cast_to=self.forward_dtype\n",
    "        )\n",
    "\n",
    "        # Positional encoding\n",
    "        log.info(\"Not using Rotary Embeddings\")\n",
    "\n",
    "        if not use_mlp_t:\n",
    "            assert pos_emb_type is not None, \"Rotary embeddings required if using attention\"\n",
    "\n",
    "        # a single network (not two separate networks)\n",
    "        reasoning_config = ReasoningBlockConfig(\n",
    "            hidden_size=hidden_size,\n",
    "            num_heads=num_heads,\n",
    "            expansion=ffn_expansion,\n",
    "            rms_norm_eps=1e-5,\n",
    "            seq_len=seq_len,\n",
    "            mlp_t=use_mlp_t,\n",
    "            puzzle_emb_ndim=puzzle_emb_dim,\n",
    "            puzzle_emb_len=puzzle_emb_len,\n",
    "            use_conv_swiglu=use_conv_swiglu,\n",
    "            use_board_swiglu=use_board_swiglu,\n",
    "            rows = max_grid_size,\n",
    "            cols = max_grid_size,\n",
    "            dropout=0.25\n",
    "        )\n",
    "\n",
    "        self.lenet = ReasoningModule(\n",
    "            layers=[ReasoningBlock(reasoning_config) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        self.lm_head = CastedLinear(hidden_size, vocab_size, bias=False)\n",
    "        self.q_head = CastedLinear(hidden_size, 1, bias=True) # learn to stop, not to continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.q_head.weight.zero_()\n",
    "            if self.q_head.bias is not None:\n",
    "                self.q_head.bias.fill_(-5.0)  # Strong negative bias\n",
    "\n",
    "        # State for carry (persisted across training steps)\n",
    "        self.carry: Optional[TRMCarry] = None\n",
    "\n",
    "        # Init states (registered buffers)\n",
    "        self.register_buffer(\n",
    "            \"z_H_init\",\n",
    "            trunc_normal_init_(torch.empty(hidden_size, dtype=self.forward_dtype), std=1),\n",
    "            persistent=True,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"z_L_init\",\n",
    "            trunc_normal_init_(torch.empty(hidden_size, dtype=self.forward_dtype), std=1),\n",
    "            persistent=True,\n",
    "        )\n",
    "\n",
    "        log.info(\"puzzle_emb_dim <= 0, not creating puzzle embeddings\")\n",
    "        self.puzzle_emb = None\n",
    "        self.puzzle_emb_len = 0\n",
    "\n",
    "        self.manual_step = 0\n",
    "        self.total_steps: float = float(\"inf\")\n",
    "\n",
    "    def _input_embeddings(self, input: torch.Tensor, puzzle_identifiers: torch.Tensor):\n",
    "        # Token embedding\n",
    "        embedding = self.input_embedding(input.to(torch.int32))\n",
    "\n",
    "        # Puzzle embeddings\n",
    "        if self.puzzle_emb_dim > 0:\n",
    "            puzzle_embedding = self.puzzle_emb(puzzle_identifiers)\n",
    "\n",
    "            pad_count = self.puzzle_emb_len * self.hidden_size - puzzle_embedding.shape[-1]\n",
    "\n",
    "            if pad_count > 0:\n",
    "                puzzle_embedding = F.pad(puzzle_embedding, (0, pad_count))\n",
    "\n",
    "            embedding = torch.cat(\n",
    "                (\n",
    "                    puzzle_embedding.view(-1, self.puzzle_emb_len, self.hidden_size),\n",
    "                    embedding,\n",
    "                ),\n",
    "                dim=-2,\n",
    "            )\n",
    "\n",
    "        # Scale\n",
    "        return self.embed_scale * embedding\n",
    "\n",
    "    def initial_carry(self, batch: Dict[str, torch.Tensor]):\n",
    "        batch_size = batch[\"input\"].shape[0]\n",
    "        device = batch[\"input\"].device\n",
    "\n",
    "        return TRMCarry(\n",
    "            inner_carry=self.empty_carry(\n",
    "                batch_size, device\n",
    "            ),  # Empty is expected, it will be reseted in first pass as all sequences are halted.\n",
    "            steps=torch.zeros((batch_size,), dtype=torch.int32, device=device),\n",
    "            halted=torch.ones((batch_size,), dtype=torch.bool, device=device),  # Default to halted\n",
    "            current_data={k: torch.empty_like(v, device=device) for k, v in batch.items()},\n",
    "        )\n",
    "\n",
    "    def empty_carry(self, batch_size: int, device: torch.device) -> TRMInnerCarry:\n",
    "        return TRMInnerCarry(\n",
    "            z_H=torch.empty(\n",
    "                batch_size,\n",
    "                self.seq_len + self.puzzle_emb_len,\n",
    "                self.hidden_size,\n",
    "                dtype=self.forward_dtype,\n",
    "                device=device,\n",
    "            ),\n",
    "            z_L=torch.empty(\n",
    "                batch_size,\n",
    "                self.seq_len + self.puzzle_emb_len,\n",
    "                self.hidden_size,\n",
    "                dtype=self.forward_dtype,\n",
    "                device=device,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def reset_carry(self, reset_flag: torch.Tensor, carry: TRMInnerCarry) -> TRMInnerCarry:\n",
    "        return TRMInnerCarry(\n",
    "            z_H=torch.where(reset_flag.view(-1, 1, 1), self.z_H_init, carry.z_H),\n",
    "            z_L=torch.where(reset_flag.view(-1, 1, 1), self.z_L_init, carry.z_L),\n",
    "        )\n",
    "\n",
    "    def inner_forward(\n",
    "        self, carry: TRMInnerCarry, batch: Dict[str, torch.Tensor]\n",
    "    ) -> Tuple[TRMInnerCarry, torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        seq_info = dict(\n",
    "            cos_sin=self.pos_embedding() if hasattr(self, \"pos_embedding\") else None,\n",
    "        )\n",
    "\n",
    "        # Input encoding\n",
    "        input_embeddings = self._input_embeddings(batch[\"input\"], batch[\"puzzle_identifiers\"])\n",
    "\n",
    "        # Forward iterations\n",
    "        z_H, z_L = carry.z_H, carry.z_L\n",
    "        # H_cycles-1 without grad\n",
    "        with torch.no_grad():\n",
    "            for _ in range(self.H_cycles - 1):\n",
    "                for _ in range(self.L_cycles):\n",
    "                    z_L = self.lenet(z_L, z_H + input_embeddings, **seq_info)\n",
    "                z_H = self.lenet(z_H, z_L, **seq_info)\n",
    "        # 1 with grad\n",
    "        for _ in range(self.L_cycles):\n",
    "            z_L = self.lenet(z_L, z_H + input_embeddings, **seq_info)\n",
    "        z_H = self.lenet(z_H, z_L, **seq_info)\n",
    "    \n",
    "        # LM Outputs\n",
    "        new_carry = TRMInnerCarry(z_H=z_H.detach(), z_L=z_L.detach())  # New carry no grad\n",
    "        output = self.lm_head(z_H)[:, self.puzzle_emb_len :] # discard puzzle embeddings\n",
    "        q_logits = self.q_head(z_H[:, 0]).to(\n",
    "            torch.float32\n",
    "        )  # Q-head; uses the first puzzle_emb position\n",
    "\n",
    "        return new_carry, output, q_logits[..., 0]\n",
    "\n",
    "    def forward(\n",
    "        self, carry: TRMCarry, batch: Dict[str, torch.Tensor]\n",
    "    ) -> Tuple[TRMCarry, Dict[str, torch.Tensor]]:\n",
    "        # Update data, carry (removing halted sequences)\n",
    "        new_inner_carry = self.reset_carry(carry.halted, carry.inner_carry)\n",
    "\n",
    "        new_steps = torch.where(carry.halted, 0, carry.steps)\n",
    "\n",
    "        new_current_data = {\n",
    "            k: torch.where(carry.halted.view((-1,) + (1,) * (batch[k].ndim - 1)), batch[k], v)\n",
    "            for k, v in carry.current_data.items()\n",
    "        }\n",
    "\n",
    "        # Forward inner model\n",
    "        new_inner_carry, logits, q_halt_logits = self.inner_forward(\n",
    "            new_inner_carry, new_current_data\n",
    "        )\n",
    "\n",
    "        outputs = {\n",
    "            \"logits\": logits,\n",
    "            \"q_halt_logits\": q_halt_logits,\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Step\n",
    "            new_steps = new_steps + 1\n",
    "            n_supervision_steps = (\n",
    "                self.N_supervision if self.training else self.N_supervision_val\n",
    "            )\n",
    "\n",
    "            is_last_step = new_steps >= n_supervision_steps\n",
    "\n",
    "            halted = is_last_step\n",
    "\n",
    "            # if training, and ACT is enabled\n",
    "            if self.training and (self.N_supervision > 1):\n",
    "                # Halt signal\n",
    "                # NOTE: During evaluation, always use max steps, this is to guarantee the same halting steps inside a batch for batching purposes\n",
    "\n",
    "                halted = halted | (q_halt_logits > 0)\n",
    "\n",
    "                # Exploration\n",
    "                min_halt_steps = (\n",
    "                    torch.rand_like(q_halt_logits) < self.halt_exploration_prob\n",
    "                ) * torch.randint_like(new_steps, low=2, high=self.N_supervision + 1)\n",
    "                halted = halted & (new_steps >= min_halt_steps)\n",
    "\n",
    "        return TRMCarry(new_inner_carry, new_steps, halted, new_current_data), outputs\n",
    "\n",
    "    def compute_loss_and_metrics(self, carry, batch):\n",
    "        \"\"\"Compute loss and metrics without circular reference.\"\"\"\n",
    "        # Get model outputs\n",
    "        new_carry, outputs = self.forward(carry, batch)\n",
    "        labels = new_carry.current_data[\"output\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs[\"preds\"] = torch.argmax(outputs[\"logits\"], dim=-1)\n",
    "\n",
    "            # Correctness\n",
    "            mask = labels != IGNORE_LABEL_ID\n",
    "            loss_counts = mask.sum(-1)\n",
    "\n",
    "            loss_divisor = loss_counts.clamp_min(1).unsqueeze(-1)  # Avoid NaNs in division\n",
    "\n",
    "            is_correct = mask & (torch.argmax(outputs[\"logits\"], dim=-1) == labels)\n",
    "            seq_is_correct = is_correct.sum(-1) == loss_counts\n",
    "\n",
    "            # Metrics (halted)\n",
    "            valid_metrics = new_carry.halted & (loss_counts > 0)\n",
    "\n",
    "            metrics = {\n",
    "                \"count\": valid_metrics.sum(),\n",
    "                \"accuracy\": torch.where(\n",
    "                    valid_metrics, (is_correct.float() / loss_divisor).sum(-1), 0\n",
    "                ).sum(),\n",
    "                \"exact_accuracy\": (valid_metrics & seq_is_correct).sum(),\n",
    "                \"q_halt_accuracy\": (\n",
    "                    valid_metrics & ((outputs[\"q_halt_logits\"].squeeze() >= 0) == seq_is_correct)\n",
    "                ).sum(),\n",
    "                \"steps\": torch.where(valid_metrics, new_carry.steps, 0).sum(),\n",
    "            }\n",
    "\n",
    "        # Compute losses: These are per-sequence losses that will be summed\n",
    "        lm_loss = (\n",
    "            stablemax_cross_entropy(\n",
    "                outputs[\"logits\"], labels, ignore_index=IGNORE_LABEL_ID, valid_mask=mask\n",
    "            )\n",
    "            / loss_divisor\n",
    "        ).sum()\n",
    "\n",
    "        q_halt_loss = F.binary_cross_entropy_with_logits(\n",
    "            outputs[\"q_halt_logits\"],\n",
    "            seq_is_correct.to(outputs[\"q_halt_logits\"].dtype),\n",
    "            reduction=\"sum\",\n",
    "        )\n",
    "        metrics.update(\n",
    "            {\n",
    "                \"lm_loss\": lm_loss.detach(),\n",
    "                \"q_halt_loss\": q_halt_loss.detach(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        total_loss = lm_loss + 0.5 * q_halt_loss\n",
    "\n",
    "        return new_carry, total_loss, metrics, new_carry.halted.all()\n",
    "\n",
    "    def log_metrics(self, metrics: dict, lr_this_step: float = None, batch_size: int = None):\n",
    "\n",
    "        # Log learning rate (will log the last optimizer's LR)\n",
    "        self.log(\"train/lr\", lr_this_step, on_step=True)\n",
    "\n",
    "        # Log metrics\n",
    "        if metrics.get(\"count\", 0) > 0:\n",
    "            with torch.no_grad():\n",
    "                count = metrics[\"count\"]\n",
    "                self.log(\"train/accuracy\", metrics.get(\"accuracy\", 0) / count, on_step=True)\n",
    "                self.log(\n",
    "                    \"train/exact_accuracy\",\n",
    "                    metrics.get(\"exact_accuracy\", 0) / count,\n",
    "                    prog_bar=True,\n",
    "                    on_step=True,\n",
    "                )\n",
    "                self.log(\n",
    "                    \"train/q_halt_accuracy\",\n",
    "                    metrics.get(\"q_halt_accuracy\", 0) / count,\n",
    "                    on_step=True,\n",
    "                )\n",
    "                self.log(\n",
    "                    \"train/steps\",\n",
    "                    metrics.get(\"steps\", 0) / count,\n",
    "                    prog_bar=True,\n",
    "                    on_step=True,\n",
    "                )\n",
    "\n",
    "                self.log(\"train/lm_loss\", metrics.get(\"lm_loss\", 0) / batch_size, on_step=True)\n",
    "                self.log(\n",
    "                    \"train/q_halt_loss\", metrics.get(\"q_halt_loss\", 0) / batch_size, on_step=True\n",
    "                )\n",
    "\n",
    "                avg_halt_steps = metrics.get(\"steps\", 0) / metrics[\"count\"]\n",
    "                early_halt_rate = avg_halt_steps < self.N_supervision\n",
    "                self.log(\"train/early_halt_rate\", early_halt_rate, on_step=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990a696",
   "metadata": {},
   "source": [
    "### Load sudoku data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bafa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Ready: 6x6 Sudoku\n",
      "Vocab Size: 9, Sequence Length: 64\n",
      "tensor([[ 2,  2,  7,  2,  9,  8],\n",
      "        [ 2,  9,  2,  2,  4,  3],\n",
      "        [ 2, 10,  2,  8,  2,  2],\n",
      "        [ 9,  2,  8,  2, 10,  2],\n",
      "        [10,  8,  4,  9,  2,  2],\n",
      "        [ 2,  3,  2,  4,  8, 10]])\n",
      "============================================================\n",
      "Sample 0 (grid_size=6x6)\n",
      "============================================================\n",
      "Givens: 19, Empty: 17\n",
      "\n",
      "Puzzle:\n",
      "+-------+-------+\n",
      "| . . 5 | . 7 6 |\n",
      "| . 7 . | . 2 1 |\n",
      "+-------+-------+\n",
      "| . 8 . | 6 . . |\n",
      "| 7 . 6 | . 8 . |\n",
      "+-------+-------+\n",
      "| 8 6 2 | 7 . . |\n",
      "| . 1 . | 2 6 8 |\n",
      "+-------+-------+\n",
      "\n",
      "Solution:\n",
      "+-------+-------+\n",
      "| 1 2 5 | 8 7 6 |\n",
      "| 6 7 8 | 5 2 1 |\n",
      "+-------+-------+\n",
      "| 2 8 1 | 6 5 7 |\n",
      "| 7 5 6 | 1 8 2 |\n",
      "+-------+-------+\n",
      "| 8 6 2 | 7 1 5 |\n",
      "| 5 1 7 | 2 6 8 |\n",
      "+-------+-------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_size = 6\n",
    "max_grid_size = 8\n",
    "dm = SudokuDataModule(\n",
    "    data_dir=None,       \n",
    "    batch_size=32,       \n",
    "    num_train_puzzles=1000,\n",
    "    num_val_puzzles=100,\n",
    "    num_test_puzzles=100,\n",
    "    grid_size=grid_size,\n",
    "    max_grid_size=max_grid_size,\n",
    "    num_workers=0,\n",
    "    seed=42\n",
    ")\n",
    "dm.setup()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "\n",
    "vocab_size = dm.vocab_size \n",
    "seq_len = dm.seq_len\n",
    "puzzle_emb_len = 0\n",
    "\n",
    "print(f\"Data Ready: {grid_size}x{grid_size} Sudoku\")\n",
    "print(f\"Vocab Size: {vocab_size}, Sequence Length: {seq_len}\")\n",
    "batch = next(iter(train_loader))\n",
    "# Visualize the first element in the batch\n",
    "inp = batch['input'][0].reshape(max_grid_size, max_grid_size)\n",
    "tgt = batch['output'][0].reshape(max_grid_size, max_grid_size)\n",
    "inp_grid = inp[:grid_size, :grid_size]\n",
    "tgt_grid = tgt[:grid_size, :grid_size]\n",
    "print(inp_grid)\n",
    "visualize_sudoku_text(batch, idx=0, grid_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163b0cb",
   "metadata": {},
   "source": [
    "### Define TRM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577a2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TRMModel(\n",
    "    hidden_size=512,\n",
    "    num_layers=1,\n",
    "    num_heads=8,\n",
    "    max_grid_size=6,\n",
    "    H_cycles=3,\n",
    "    L_cycles=6,\n",
    "    N_supervision=16,\n",
    "    N_supervision_val=16,\n",
    "    ffn_expansion=4,\n",
    "    learning_rate=1e-4,\n",
    "    learning_rate_emb=1e-4,\n",
    "    weight_decay=1.0,\n",
    "    warmup_steps=2000,\n",
    "    halt_exploration_prob=0.1,\n",
    "    puzzle_emb_dim=0,\n",
    "    puzzle_emb_len=0,\n",
    "    rope_theta=10000,\n",
    "    pos_emb_type=None, # IMPORTANT: since use_mlp_t=True\n",
    "    use_mlp_t=True,\n",
    "    use_conv_swiglu=False,\n",
    "    use_board_swiglu=False,\n",
    "    lr_min_ratio=0.01,\n",
    "    use_muon=False,\n",
    "    vocab_size=3+dm.max_grid_size,\n",
    "    num_puzzles=0,\n",
    "    batch_size=train_loader.batch_size,\n",
    "    pad_value=getattr(dm, \"pad_value\", 0),\n",
    "    seq_len=seq_len,\n",
    "    output_dir=None,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f393ae6",
   "metadata": {},
   "source": [
    "### Define TRM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fffc3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = model.learning_rate\n",
    "wd = model.weight_decay\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=base_lr,\n",
    "    weight_decay=wd,\n",
    "    betas=(0.9, 0.95),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49af2d8",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8b8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_batch_to_device(batch, device):\n",
    "    return {k: (v.to(device, non_blocking=True) if torch.is_tensor(v) else v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73f32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, carry, batch, optimizer, *, total_steps, grad_clip=1.0):\n",
    "    model.train()\n",
    "    batch_size = batch[\"input\"].shape[0]\n",
    "\n",
    "    if carry is None:\n",
    "        carry = model.initial_carry(batch)\n",
    "\n",
    "    carry, loss, metrics, _ = model.compute_loss_and_metrics(carry, batch)\n",
    "    (loss / batch_size).backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n",
    "\n",
    "    current_step = model.manual_step\n",
    "    \n",
    "    # Compute learning rate\n",
    "    if current_step < model.warmup_steps:\n",
    "        lr_this_step = compute_lr(\n",
    "            base_lr=model.learning_rate,\n",
    "            lr_warmup_steps=model.warmup_steps,\n",
    "            lr_min_ratio=model.lr_min_ratio,\n",
    "            current_step=current_step,\n",
    "            total_steps=total_steps,\n",
    "        )\n",
    "    else:\n",
    "        lr_this_step = model.learning_rate\n",
    "\n",
    "    # Update learning rate in ALL param groups\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr_this_step\n",
    "    \n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if torch.isnan(metrics[\"lm_loss\"]):\n",
    "        raise RuntimeError(f\"LM loss is NaN at step {model.manual_step}\")\n",
    "\n",
    "    model.manual_step += 1\n",
    "\n",
    "    count = float(metrics[\"count\"].item())\n",
    "    logs = {\n",
    "        \"train/loss\": float(loss.item()),\n",
    "        \"train/lm_loss\": float((metrics[\"lm_loss\"] / batch_size).item()),\n",
    "        \"train/q_halt_loss\": float((metrics[\"q_halt_loss\"] / batch_size).item()),\n",
    "        \"train/lr\": float(lr_this_step),  # Return actual LR\n",
    "    }\n",
    "    if count > 0:\n",
    "        logs.update({\n",
    "            \"train/accuracy\": float((metrics[\"accuracy\"] / metrics[\"count\"]).item()),\n",
    "            \"train/exact_accuracy\": float((metrics[\"exact_accuracy\"] / metrics[\"count\"]).item()),\n",
    "            \"train/q_halt_accuracy\": float((metrics[\"q_halt_accuracy\"] / metrics[\"count\"]).item()),\n",
    "            \"train/steps\": float((metrics[\"steps\"] / metrics[\"count\"]).item()),\n",
    "        })\n",
    "    return carry, loss, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a712438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000 | batch 0000 | loss 83.0023 | exact nan | steps nan | lr 8.01e-05\n",
      "epoch 001 | batch 0000 | loss 73.1257 | exact 0.0000 | steps 16.00 | lr 8.16e-05\n",
      "epoch 002 | batch 0000 | loss 66.1042 | exact nan | steps nan | lr 8.32e-05\n",
      "epoch 003 | batch 0000 | loss 61.8749 | exact nan | steps nan | lr 8.47e-05\n",
      "epoch 004 | batch 0000 | loss 56.6923 | exact nan | steps nan | lr 8.63e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m batch = move_batch_to_device(batch, device)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# If you want to reset carry every batch (instead of persisting), uncomment:\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# train_carry = None\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_carry, loss, logs = \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_carry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_idx % print_every == \u001b[32m0\u001b[39m:\n\u001b[32m     19\u001b[39m     msg = (\n\u001b[32m     20\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs[\u001b[33m'\u001b[39m\u001b[33mtrain/loss\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs[\u001b[33m'\u001b[39m\u001b[33mtrain/lr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtraining_step\u001b[39m\u001b[34m(model, carry, batch, optimizer, total_steps, grad_clip)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m carry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      6\u001b[39m     carry = model.initial_carry(batch)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m carry, loss, metrics, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss_and_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m (loss / batch_size).backward()\n\u001b[32m     10\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 299\u001b[39m, in \u001b[36mTRMModel.compute_loss_and_metrics\u001b[39m\u001b[34m(self, carry, batch)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute loss and metrics without circular reference.\"\"\"\u001b[39;00m\n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Get model outputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m new_carry, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m labels = new_carry.current_data[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 261\u001b[39m, in \u001b[36mTRMModel.forward\u001b[39m\u001b[34m(self, carry, batch)\u001b[39m\n\u001b[32m    255\u001b[39m new_current_data = {\n\u001b[32m    256\u001b[39m     k: torch.where(carry.halted.view((-\u001b[32m1\u001b[39m,) + (\u001b[32m1\u001b[39m,) * (batch[k].ndim - \u001b[32m1\u001b[39m)), batch[k], v)\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m carry.current_data.items()\n\u001b[32m    258\u001b[39m }\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# Forward inner model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m new_inner_carry, logits, q_halt_logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_inner_carry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_current_data\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m outputs = {\n\u001b[32m    266\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m\"\u001b[39m: logits,\n\u001b[32m    267\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mq_halt_logits\u001b[39m\u001b[33m\"\u001b[39m: q_halt_logits,\n\u001b[32m    268\u001b[39m }\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Step\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 235\u001b[39m, in \u001b[36mTRMModel.inner_forward\u001b[39m\u001b[34m(self, carry, batch)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# 1 with grad\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.L_cycles):\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     z_L = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_H\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mseq_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m z_H = \u001b[38;5;28mself\u001b[39m.lenet(z_H, z_L, **seq_info)\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# LM Outputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 164\u001b[39m, in \u001b[36mReasoningModule.forward\u001b[39m\u001b[34m(self, hidden_states, input_injection, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m hidden_states = hidden_states + input_injection\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     hidden_states = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/bayesian-nano-trm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 150\u001b[39m, in \u001b[36mReasoningBlock.forward\u001b[39m\u001b[34m(self, cos_sin, hidden_states)\u001b[39m\n\u001b[32m    147\u001b[39m     hidden_states = rms_norm(hidden_states + attn_out, variance_epsilon=\u001b[38;5;28mself\u001b[39m.norm_eps)\n\u001b[32m    149\u001b[39m mlp_out = \u001b[38;5;28mself\u001b[39m.mlp(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m hidden_states = \u001b[43mrms_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_eps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mrms_norm\u001b[39m\u001b[34m(hidden_states, variance_epsilon)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrms_norm\u001b[39m(hidden_states: torch.Tensor, variance_epsilon: \u001b[38;5;28mfloat\u001b[39m) -> torch.Tensor:\n\u001b[32m     50\u001b[39m     input_dtype = hidden_states.dtype\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     hidden_states = \u001b[43mhidden_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     variance = hidden_states.square().mean(-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     54\u001b[39m     hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "check_val_every_n_epoch = 10\n",
    "print_every = 50\n",
    "max_epochs = 100\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = steps_per_epoch * max_epochs\n",
    "train_carry = None\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = move_batch_to_device(batch, device)\n",
    "        # If you want to reset carry every batch (instead of persisting), uncomment:\n",
    "        # train_carry = None\n",
    "\n",
    "        train_carry, loss, logs = training_step(\n",
    "            model, train_carry, batch, optimizer, total_steps=total_steps, grad_clip=1.0\n",
    "        )\n",
    "\n",
    "        if batch_idx % print_every == 0:\n",
    "            msg = (\n",
    "                f\"epoch {epoch:03d} | batch {batch_idx:04d} | \"\n",
    "                f\"loss {logs['train/loss']:.4f} | \"\n",
    "                f\"exact {logs.get('train/exact_accuracy', float('nan')):.4f} | \"\n",
    "                f\"steps {logs.get('train/steps', float('nan')):.2f} | \"\n",
    "                f\"lr {logs['train/lr']:.2e}\"\n",
    "            )\n",
    "            print(msg)\n",
    "    \"\"\"\n",
    "    if (epoch + 1) % check_val_every_n_epoch == 0:\n",
    "        val_logs = run_validation_epoch(model, val_loader, device)\n",
    "        print(\n",
    "            f\"[VAL @ epoch {epoch:03d}] \"\n",
    "            f\"exact={val_logs['val/exact_accuracy']:.4f} \"\n",
    "            f\"acc={val_logs['val/accuracy']:.4f} \"\n",
    "            f\"steps={val_logs['val/steps']:.2f} \"\n",
    "            f\"loss={val_logs['val/loss']:.4f}\"\n",
    "        )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c980f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation_step(model, batch):\n",
    "    \"\"\"\n",
    "    Mirrors your Lightning validation_step:\n",
    "    - fresh carry\n",
    "    - loop until all_halted\n",
    "    - accumulate metrics then average\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch_size = batch[\"input\"].shape[0]\n",
    "    carry = model.initial_carry(batch)\n",
    "\n",
    "    accumulated = {}\n",
    "    total_loss = 0.0\n",
    "    n_steps = 0\n",
    "\n",
    "    while True:\n",
    "        carry, loss, metrics, all_halted = model.compute_loss_and_metrics(carry, batch)\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            accumulated[k] = accumulated.get(k, 0.0) + float(v.item())\n",
    "\n",
    "        total_loss += float(loss.item())\n",
    "        n_steps += 1\n",
    "\n",
    "        if bool(all_halted.item()):\n",
    "            break\n",
    "\n",
    "    count = accumulated.get(\"count\", float(batch_size))\n",
    "    if count > 0:\n",
    "        return {\n",
    "            \"val/loss\": total_loss / (n_steps * batch_size),\n",
    "            \"val/accuracy\": accumulated.get(\"accuracy\", 0.0) / count,\n",
    "            \"val/exact_accuracy\": accumulated.get(\"exact_accuracy\", 0.0) / count,\n",
    "            \"val/q_halt_accuracy\": accumulated.get(\"q_halt_accuracy\", 0.0) / count,\n",
    "            \"val/steps\": accumulated.get(\"steps\", 0.0) / count,\n",
    "            \"val/lm_loss\": accumulated.get(\"lm_loss\", 0.0) / (n_steps * batch_size),\n",
    "            \"val/q_halt_loss\": accumulated.get(\"q_halt_loss\", 0.0) / (n_steps * batch_size),\n",
    "        }\n",
    "    else:\n",
    "        return {k: 0.0 for k in [\"val/loss\",\"val/accuracy\",\"val/exact_accuracy\",\"val/q_halt_accuracy\",\"val/steps\",\"val/lm_loss\",\"val/q_halt_loss\"]}\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_validation_epoch(model, val_loader, device):\n",
    "    totals = {\n",
    "        \"val/loss\": 0.0,\n",
    "        \"val/accuracy\": 0.0,\n",
    "        \"val/exact_accuracy\": 0.0,\n",
    "        \"val/q_halt_accuracy\": 0.0,\n",
    "        \"val/steps\": 0.0,\n",
    "        \"val/lm_loss\": 0.0,\n",
    "        \"val/q_halt_loss\": 0.0,\n",
    "    }\n",
    "    n = 0\n",
    "    for batch in val_loader:\n",
    "        batch = move_batch_to_device(batch, device)\n",
    "        out = validation_step(model, batch)\n",
    "        for k in totals:\n",
    "            totals[k] += out[k]\n",
    "        n += 1\n",
    "    for k in totals:\n",
    "        totals[k] /= max(n, 1)\n",
    "    return totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f445cdd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nano-trm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
